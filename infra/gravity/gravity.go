package gravity

import (
	"bytes"
	"context"
	"fmt"
	"log"
	"text/template"
	"time"

	"github.com/gravitational/robotest/infra"
	sshutils "github.com/gravitational/robotest/lib/ssh"
	"github.com/gravitational/robotest/lib/utils"
	"github.com/gravitational/trace"

	"golang.org/x/crypto/ssh"
)

// Gravity is interface to remote gravity CLI
type Gravity interface {
	// Install operates on initial master node
	Install(ctx context.Context, param InstallCmd) error
	// Retrieve status
	Status(ctx context.Context) (*GravityStatus, error)
	// OfflineUpdate tries to upgrade application version
	OfflineUpdate(ctx context.Context, installerUrl string) error
	// Join asks to join existing cluster (or installation in progress)
	Join(ctx context.Context, param JoinCmd) error
	// Leave requests current node leave a cluster
	Leave(ctx context.Context, graceful bool) error
	// Remove requests cluster to evict a given node
	Remove(ctx context.Context, node string, graceful bool) error
	// Uninstall will wipe gravity installation from node
	Uninstall(ctx context.Context) error
	// Poweroff will power off the node
	PowerOff(ctx context.Context, graceful bool) error
	// Reboot will reboot this node and wait until it will become available again
	Reboot(ctx context.Context, graceful bool) error
	// Node returns underlying VM instance
	Node() infra.Node
	// Client returns SSH client to VM instance
	Client() *ssh.Client
	// Text representation
	String() string
	// Will log using extended info such as current tag, node info, etc
	Logf(format string, args ...interface{})
}

const (
	// Force an operation
	Force = false
	// Graceful completion of operation
	Graceful = true
)

// InstallCmd install parameters passed to first node
type InstallCmd struct {
	// Token is required to join cluster
	Token string
	// Cluster is Optional name of the cluster. Autogenerated if not set.
	Cluster string
	// Flavor is (Optional) Application flavor. See Application Manifest for details.
	Flavor string
	// K8SConfig is (Optional) File with Kubernetes resources to create in the cluster during installation.
	K8SConfig string
	// PodNetworkCidr is (Optional) CIDR range Kubernetes will be allocating node subnets and pod IPs from. Must be a minimum of /16 so Kubernetes is able to allocate /24 to each node. Defaults to 10.244.0.0/16.
	PodNetworkCIDR string
	// ServiceCidr (Optional) CIDR range Kubernetes will be allocating service IPs from. Defaults to 10.100.0.0/16.
	ServiceCIDR string
}

// JoinCmd represents various parameters for Join
type JoinCmd struct {
	// InstallDir is set automatically
	InstallDir string
	// PeerAddr is other node (i.e. master)
	PeerAddr string
	Token    string
	Role     string
}

// GravityStatus is serialized form of `gravity status` CLI.
type GravityStatus struct {
	Application string
	Cluster     string
	Status      string
	// Token is secure token which prevents rogue nodes from joining the cluster during installation.
	Token string `validation:"required"`
	// Nodes defines nodes the cluster observes
	Nodes []string
}

type gravity struct {
	fromConfig   *ProvisionerConfig
	logFn        utils.LogFnType
	node         infra.Node
	installDir   string
	dockerDevice string
	ssh          *ssh.Client
}

const retrySSH = time.Second * 10

// waits for SSH to be up on node and returns client
func sshClient(ctx context.Context, logFn utils.LogFnType, node infra.Node) (*ssh.Client, error) {
	for {
		client, err := node.Client()

		if err == nil {
			return client, nil
		}

		logFn("waiting for SSH on %s, retry in %v, error was %v", node.Addr(), retrySSH, err)
		select {
		case <-ctx.Done():
			return nil, trace.Wrap(err, "SSH timed out dialing %s", node.Addr())
		case <-time.After(retrySSH):
		}
	}
}

// Logf logs simultaneously to stdout and testing interface
func (g *gravity) Logf(format string, args ...interface{}) {
	log.Printf("%s [%v] %s", g.fromConfig.Tag(), g, fmt.Sprintf(format, args...))
	g.logFn("[%v] %s", g, fmt.Sprintf(format, args...))
}

// String returns public and private addresses of the node
func (g *gravity) String() string {
	return fmt.Sprintf("%s %s", g.node.PrivateAddr(), g.node.Addr())
}

func (g *gravity) Node() infra.Node {
	return g.node
}

// Client returns SSH client to the node
func (g *gravity) Client() *ssh.Client {
	return g.ssh
}

// Install runs gravity install with params
func (g *gravity) Install(ctx context.Context, param InstallCmd) error {
	cmd := fmt.Sprintf("cd %s && sudo ./gravity install --advertise-addr=%s --token=%s --flavor=%s --docker-device=%s",
		g.installDir, g.node.PrivateAddr(), param.Token, param.Flavor, g.dockerDevice)

	err := sshutils.Run(ctx, g, cmd, nil)
	return trace.Wrap(err, cmd)
}

// Status queries cluster status
func (g *gravity) Status(ctx context.Context) (*GravityStatus, error) {
	cmd := fmt.Sprintf("cd %s && sudo ./gravity status", g.installDir)
	status, exit, err := sshutils.RunAndParse(ctx, g, cmd, nil, parseStatus)

	if err != nil {
		return nil, trace.Wrap(err, cmd)
	}

	if exit != 0 {
		return nil, trace.Errorf("[%s/%s] %s returned %d",
			g.Node().PrivateAddr(), g.Node().Addr(), cmd, exit)
	}

	return status.(*GravityStatus), nil
}

func (g *gravity) OfflineUpdate(ctx context.Context, installerUrl string) error {
	return nil
}

// autoVals are set by command itself based on configuration
type autoVals struct{ InstallDir, PrivateAddr, DockerDevice string }

// cmdEx are extended parameters passed to gravity
type cmdEx struct {
	P   autoVals
	Cmd interface{}
}

var joinCmdTemplate = template.Must(
	template.New("gravity_join").Parse(
		`cd {{.P.InstallDir}} && sudo ./gravity join {{.Cmd.PeerAddr}} \
		--advertise-addr={{.P.PrivateAddr}} --token={{.Cmd.Token}} \
		--role={{.Cmd.Role}} --docker-device={{.P.DockerDevice}}`))

func (g *gravity) Join(ctx context.Context, cmd JoinCmd) error {
	var buf bytes.Buffer
	err := joinCmdTemplate.Execute(&buf, cmdEx{
		P:   autoVals{g.installDir, g.Node().PrivateAddr(), g.dockerDevice},
		Cmd: cmd,
	})
	if err != nil {
		return trace.Wrap(err, buf.String())
	}

	err = sshutils.Run(ctx, g, buf.String(), nil)
	return trace.Wrap(err, cmd)
}

// Leave makes given node leave the cluster
func (g *gravity) Leave(ctx context.Context, graceful bool) error {
	var cmd string
	if graceful {
		cmd = fmt.Sprintf(`cd %s && sudo ./gravity leave --debug --confirm`, g.installDir)
	} else {
		cmd = fmt.Sprintf(`cd %s && sudo ./gravity leave --debug --confirm --force`, g.installDir)
	}

	err := sshutils.Run(ctx, g, cmd, nil)
	return trace.Wrap(err, cmd)
}

// Remove ejects node from cluster
func (g *gravity) Remove(ctx context.Context, node string, graceful bool) error {
	var cmd string
	if graceful {
		cmd = fmt.Sprintf(`cd %s && sudo ./gravity remove --confirm %s`, g.installDir, node)
	} else {
		cmd = fmt.Sprintf(`cd %s && sudo ./gravity remove --confirm --force %s`, g.installDir, node)
	}
	err := sshutils.Run(ctx, g, cmd, nil)
	return trace.Wrap(err, cmd)
}

// Uninstall removes gravity installation. It requires Leave beforehand
func (g *gravity) Uninstall(ctx context.Context) error {
	cmd := fmt.Sprintf(`cd %s && sudo ./gravity system uninstall --confirm`, g.installDir)
	err := sshutils.Run(ctx, g, cmd, nil)
	return trace.Wrap(err, cmd)
}

// PowerOff forcibly halts a machine
func (g *gravity) PowerOff(ctx context.Context, graceful bool) error {
	var cmd string
	if graceful {
		cmd = "sudo shutdown -h now"
	} else {
		cmd = "sudo poweroff -f"
	}

	sshutils.RunAndParse(ctx, g, cmd, nil, nil)
	// TODO: reliably destinguish between force close of SSH control channel and command being unable to run
	return nil
}

// Reboot gracefully restarts a machine and waits for it to become available again
func (g *gravity) Reboot(ctx context.Context, graceful bool) error {
	var cmd string
	if graceful {
		cmd = "sudo shutdown -r now"
	} else {
		cmd = "sudo reboot -f"
	}
	sshutils.RunAndParse(ctx, g, cmd, nil, nil)
	// TODO: reliably destinguish between force close of SSH control channel and command being unable to run

	client, err := sshClient(ctx, g.logFn, g.Node())
	if err != nil {
		return trace.Wrap(err, "SSH reconnect")
	}

	g.ssh = client
	return nil
}
